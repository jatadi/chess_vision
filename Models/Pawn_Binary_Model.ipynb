{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EGTgzySf5xgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55a27c4-219f-4f26-ffe7-097065f9ef4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Importing Libraries\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Paths for Pawn Project\n",
        "dataset_dir = \"/content/gdrive/My Drive/Datasets/Chess_Vision\"\n",
        "input_folder_binary = \"/content/gdrive/My Drive/Datasets/Chess_Vision_Binary_Pawn_Input\"\n",
        "output_folder = \"/content/gdrive/My Drive/Datasets/Chess_Vision_Binary_Pawn\""
      ],
      "metadata": {
        "id": "vLX-xwGB51OD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Copy Files (reuse existing function)\n",
        "def copy_files(src, dst):\n",
        "    os.makedirs(dst, exist_ok=True)\n",
        "    for file in os.listdir(src):\n",
        "        shutil.copy(os.path.join(src, file), dst)\n",
        "\n",
        "# Prepare Dataset for Pawn\n",
        "non_pawn_dir = os.path.join(dataset_dir, \"Non_Pawn\")\n",
        "if not os.path.exists(non_pawn_dir):\n",
        "    os.makedirs(non_pawn_dir)\n",
        "\n",
        "other_pieces = [\"Rook\", \"Bishop\", \"Queen\", \"Knight\", \"King\"]\n",
        "num_images_per_class = 22\n",
        "\n",
        "# Copy images for Non_Pawn class\n",
        "if len(os.listdir(non_pawn_dir)) < 110:\n",
        "    for piece in other_pieces:\n",
        "        piece_dir = os.path.join(dataset_dir, piece)\n",
        "        images = random.sample(os.listdir(piece_dir), num_images_per_class)\n",
        "        for img in images:\n",
        "            shutil.copy(os.path.join(piece_dir, img), os.path.join(non_pawn_dir, f\"{piece}_{img}\"))"
      ],
      "metadata": {
        "id": "nLwkpd7V6DDK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count Images for Pawn\n",
        "pawn_count = len(os.listdir(os.path.join(dataset_dir, \"Pawn\")))\n",
        "non_pawn_count = len(os.listdir(non_pawn_dir))\n",
        "print(f\"Number of Pawn images: {pawn_count}\")\n",
        "print(f\"Number of Non_Pawn images: {non_pawn_count}\")"
      ],
      "metadata": {
        "id": "Pb9Fs86_6idd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa29e50f-c3dd-4fc1-8959-75fe2654f433"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Pawn images: 107\n",
            "Number of Non_Pawn images: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Input Directory for Binary Classification\n",
        "os.makedirs(input_folder_binary, exist_ok=True)\n",
        "copy_files(os.path.join(dataset_dir, \"Pawn\"), os.path.join(input_folder_binary, \"Pawn\"))\n",
        "copy_files(non_pawn_dir, os.path.join(input_folder_binary, \"Non_Pawn\"))\n",
        "\n",
        "# Split Dataset\n",
        "splitfolders.ratio(input_folder_binary, output=output_folder, seed=42, ratio=(.7, .2, .1))"
      ],
      "metadata": {
        "id": "dahv9k1z62-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70758e3f-25bf-4aaa-a9ca-509eda9a1bab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 207 files [00:05, 37.26 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)  # Only rescaling for validation and test sets\n",
        "\n",
        "# Load images from directory and apply transformations\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(output_folder, 'train'),\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = val_test_datagen.flow_from_directory(\n",
        "    os.path.join(output_folder, 'val'),\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    os.path.join(output_folder, 'test'),\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False  # Important for evaluation\n",
        ")\n"
      ],
      "metadata": {
        "id": "16e0bYWq7D_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0851ccd3-abb1-41df-8531-03234b1e674f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 142 images belonging to 2 classes.\n",
            "Found 41 images belonging to 2 classes.\n",
            "Found 22 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load VGG16 model without the top layer\n",
        "base_model = VGG16(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "base_model.trainable = False  # Freeze the base model layers\n",
        "\n",
        "# Define the input layer\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "\n",
        "# Pass the image through the base model\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "# Flatten the output of the base model\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Additional layers\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)  # Updated dropout rate\n",
        "\n",
        "# Output layer for binary classification\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the model\n",
        "binary_model = Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "binary_model.compile(loss=\"binary_crossentropy\",\n",
        "                     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # Updated learning rate\n",
        "                     metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "j2-5Q_Ls7NhH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16621d01-e9f1-4d2b-92a2-b53718bb5321"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "model_checkpoint = ModelCheckpoint('/content/gdrive/My Drive/Datasets/pawn_detector_best_model.h5', save_best_only=True,\n",
        "                                   monitor='val_accuracy')\n",
        "#model_checkpoint = ModelCheckpoint('/content/gdrive/My Drive/Datasets/pawn_best_model',\n",
        "                                   #save_best_only=True, monitor='val_accuracy', save_format='tf')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.01)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "SnHSrn6L7S_o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "history = binary_model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[model_checkpoint, reduce_lr, early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "id": "d8Hnwrmu7Z3G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65729b9-b4f5-4651-886f-bd59efd23cdb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - ETA: 0s - loss: 0.7949 - accuracy: 0.5634 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 110s 25s/step - loss: 0.7949 - accuracy: 0.5634 - val_loss: 0.4984 - val_accuracy: 0.8780 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 125s 26s/step - loss: 0.5507 - accuracy: 0.7042 - val_loss: 0.3885 - val_accuracy: 0.9268 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 117s 27s/step - loss: 0.4299 - accuracy: 0.7887 - val_loss: 0.3052 - val_accuracy: 0.9512 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 129s 27s/step - loss: 0.3215 - accuracy: 0.8803 - val_loss: 0.2693 - val_accuracy: 0.9268 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 122s 29s/step - loss: 0.2580 - accuracy: 0.9296 - val_loss: 0.2298 - val_accuracy: 0.9512 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 123s 26s/step - loss: 0.2522 - accuracy: 0.9014 - val_loss: 0.2144 - val_accuracy: 0.9512 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 109s 23s/step - loss: 0.2247 - accuracy: 0.9225 - val_loss: 0.2260 - val_accuracy: 0.9512 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 106s 24s/step - loss: 0.1683 - accuracy: 0.9648 - val_loss: 0.1767 - val_accuracy: 0.9512 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 125s 26s/step - loss: 0.1711 - accuracy: 0.9366 - val_loss: 0.1857 - val_accuracy: 0.9512 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 126s 30s/step - loss: 0.1123 - accuracy: 0.9718 - val_loss: 0.2251 - val_accuracy: 0.9024 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "test_loss, test_accuracy = binary_model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Generate Predictions and Evaluate\n",
        "probabilities = binary_model.predict(test_generator)\n",
        "predictions = [1 if x > 0.5 else 0 for x in probabilities.ravel()]\n",
        "true_classes = test_generator.classes\n",
        "report = classification_report(true_classes, predictions, target_names=['Non_Pawn', 'Pawn'])\n",
        "print(report)\n",
        "\n",
        "# ROC-AUC Score and Curve\n",
        "roc_auc = roc_auc_score(true_classes, probabilities)\n",
        "fpr, tpr, thresholds = roc_curve(true_classes, probabilities)\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Plot Training History\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DndX7FsN7fX6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}